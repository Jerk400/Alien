\documentclass{intech}

%\usepackage{your_package}  %if you need custom package
%\usepackage[notquote]{hanging}


% * CHAPTER NUMBER * BOOK NAME * AUTHOR(S) NAME *****************************
\setcounter{chapter}{0} % It will be set by technical editor.

\booktitle{Will-be-set-by-IN-TECH}%

\chaptertitle{Grid Computing in High Energy Physics Experiments} % You know your chapter title?

\authors{Dagmar~Adamov\'a}
%
\affiliation{Nuclear Physics Institute, \v{R}e\v{z} near Prague}
%
\country{Czech Republic}

% uncomment the next three or six lines, when authors are from different university, company or country

%\secondauthors{Latchezar~Betev}
%
%\secondaffiliation{CERN}
%
%\secondcountry{Switzerland}

%\thirdauthors{}
%\thirdaffiliation{}
%\thirdcountry{}

% END * CHAPTER NUMBER * BOOK NAME * AUTHOR(S) NAME *************************

\include{adamova01}

%%%%%%%%%%%%%%%%%%% section 2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\include{adamova02}

%%%%%%%%%%%%%%%%%%%%%%%%% section 3 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\include{adamova03}

%%%%%%%%%%%%%%%%%%%% section 4 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\include{adamova04}

%%%%%%%%%%%%%%%%%%%% section 5 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{AliEn}

AliEn [26] is a set of middleware tools and services which represents
an implementation of the ALICE distributed computing environment
integrated in the WLCG environment. AliEn has been under a constant
development by ALICE since about 2001 and was deployed over the
ALICE Grid infrastructure right from the start. One of the important
features is the set of interfaces to other Grid implementations like
gLite [53], ARC [54] and OSG [15].

AliEn was initially developed as a distributed production
environment for the simulation, reconstruction, and analysis of
Physics data. Since it was put in the production in 2001, ALICE has
been using AliEn before the start of  the real data taking for
distributed production cycles of Monte-Carlo simulated raw data,
including subsequent reconstruction and analysis, during the regular
Physics Data Challenges. Since 2005, AliEn has been used also for
end-user analysis.  Since December 2007, when the ALICE detector
started operation taking cosmic data, AliEn has been used also for
management of the raw data.  Since the LHC startup in 2009, millions
of jobs have been successfully processed using the AliEn services
and tools.

AliEn developers provided the users with a client/interface - ``alien
shel'' [55] and a set of plugins designed for the end users' job
submission and handling. These tools together with the tools
provided by the ALICE Grid monitoring framework MonALISA [40] hide
the complexity and heterogenity of the underlying Grid services from
the end-user while facing the rapid development of the Grid
technologies.

AliEn is a lightweight Open Source Grid framework built around Open
Source components using the combination of standard network
protocols, a Web Service and Distributed Agent Model [26]. The basic
AliEn components include:
%
\begin{itemize}
\item AliEn File Catalogue with metadata capabilities
\item  Data management tools for data transfers and storage
\item Authentication, authorization and auditing services
\item Workload management system
\item Storage and computing elements
\item Information services
\item Site services
\item Command line interface - the AliEn shell aliensh
\item ROOT interface
\item Grid and job monitoring
\item Interfaces to other Grids
\end{itemize}

AliEn was primarily developed by ALICE, however it was adopted also
by a couple of other Virtual Organizations like e.g. PANDA [56].

\subsection{File Catalogue (FC)}
%
The File Catalogue is one of the key components of the AliEn suite.
It provides a hierarchical structure (like a UNIX File system) and
is designed to allow each directory node in the hierarchy to be
supported by different database engines, running on different hosts.
This building on top of several databases allows to add another
database to expand the catalogue namespace and assures scalability
of the system and allow growth of the catalogue as the files
accumulate over the years.

Unlike real file systems, the FC does not own the files; it is a
metadata catalogue on the Logical File Names (LFN) and only keeps an
association/mapping between the LFNs and (possibly multiple)
Physical File Names (PFN) of real files on a storage system. PFNs
describe the physical location of the files and include the access
protocol (rfio, xrootd), the name of the AliEn Storage Element and
the path to the local file. The system supports file replication and
caching.

The FC provides also a mapping between the LFNs and Globally Unique
Identifiers (GUID). The labeling of each file with the GUID allows
for the asynchronous caching. The write-once strategy combined with
GUID labeling guarantees the identity of files with the same GUID
label in different caches. It is possible to automatically construct
PFNs : to store only the GUID and Storage Index and the Storage
Element builds the PFN from the GUID. There are two independent
catalogues: LFN->GUID and GUID->PFN. A schema of the AliEn FC is
shown in Figure~\ref{fig15}.

%fig15
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig15.eps} %    ** if .eps don't need extension
\caption{AliEn File Catalogue}\label{fig15}
\end{figure}


\subsection{Authentication and Authorization}
%
The authentication uses the Grid Access Service (GAS) [57] which is
functioning as an ad-hoc user portal. Before connecting to GAS, a
user creates a proxy certificate and stores it in the myproxy server
and submits a session request. In addition to myproxy service, the
Virtual Organization Membership Service [58] is also used. The system
is able to take into account user roles when creating the GAS
interface.

\subsection{Workload Management System}
%
AliEn's Workload Management System (WMS) is based on the pull
architecture and is a set of central components (Task Queue, Job
Optimizer, Job Broker) and site components (Computing Element (CE),
Cluster Monitor, MonALISA, Package Manager). The pull architecture
has an advantage with respect to the push one: WMS does not have to
know actual status of all resources, which is crucial for large
flexible Grids. When the push architecture is used, WMS must get,
keep and analyze a huge amount of status data just to assign a job,
which becomes difficult in the expanding grid environment. In the
pull architecture, local agents (pilot status-checking test jobs)
running at individual sites ask for  real jobs after having checked
the local hardware and software conditions and found them
appropriate for the processing of the job. Thus the WMS only deals
with the requests of local pilot jobs, so called Job Agents (JA), to
assign appropriate real jobs. The descriptions of jobs in the form
of ClassAds are managed by the central Task Queue.

At each site, there are running AliEn services CE, ClusterMonitor,
Package Manager (PackMan) and a MonALISA client. The AliEn CE
automatically generates and submits to the local WLCG CE, or
eventually to an appropriate external Resource Broker or WMS, the
local Job Agents. The ClusterMonitor manages the connections between
the site and central services, so there is only one connection from
each site. The AliEn WMS can be integrated with WLCG or other Grid
systems WMS and the job management is organized by a collaboration
of both systems. Sites using AliEn are as a rule running some
services of the gLite, ARC or OSG, like e.g. CREAM-CE (see section
3).  The AliEn CE is in this case combined with the CREAM-CE in the
job submission machinery. Schemas of the job submission procedure in
AliEn are shown in Figures~\ref{fig16} and~\ref{fig17}.

%fig16
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig16.eps} %    ** if .eps don't need extension
\caption{AliEn + WLCG services}\label{fig16}
\end{figure}



%fig17
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig17.eps} %    ** if .eps don't need extension
\caption{The Job Agent model in AliEn}\label{fig17}
\end{figure}



\subsection{Jobs}
%
When a job is submitted by a user, its description in the form of a
ClassAd is kept in the central TQ (handling also priorities and
quotas) where it waits for a suitable Job Agent for execution.  The
requirements of all jobs waiting in the central TQ are checked by
the central Job Optimizer. It can change some requirements, or
suggest data transfers so it would be more likely that some Job
Agent picks up the job.

After it has been submitted, a job gets through several stages, see
[59].  The information about running processes is kept also in the
AliEn FC. Each job is given a unique id and a corresponding
directory where it can register temporary files, standard input and
output as well as all job products. So while the information on job
submission and status is centralized, the decisions concerning the
actual submission is decentralized: sites decide which job to
"pull". The JAs provide a job-wrapper, a standard environment
allowing a virtualization of resources. The whole job submission and
processing chain is extensively monitored so a user can any time get
the information on the status of his/her jobs.

\subsection{Site services}
%
As mentioned efore, at each ALICE site are
running AliEn services CE, ClusterMonitor, PackMan and MonALISA.
These services are running on a dedicated machine, so called VOBOX
described in section 3.

The AliEn site CE is usually associated with the local batch system.
It is periodically submitting testing pilot jobs (Job Agents)  to
the local WLCG CE or an appropriate external Resource Broker or WMS.
The role of the Job Agents is to verify the local hardware and
software capacities at the site. After the usual matchmaking
procedure, the JA is sent, through the site CE, into the local batch
queue and then to a local Worker Node (WN). After its startup, the
JA performs its task and in the case of a positive checkup, the JA
requests a "real" job from the central Task Queue via the AliEn Job
Broker, or dies otherwise.

The PackMan automates the process of installation, upgrades,
configuration and removal of the ALICE software packages from the
shared software area on the site. It also advertises known/installed
packages. The packages are installed on demand, when requested by a
Job Agent running on a Worker Node or during the central software
deployment over the Grid sites. If a package is not already
installed the PackMan would install it along with its dependencies
and return a string with commands that client has to execute to
configure the package and all its dependencies. The PackMan manages
the local disk cache and cleans it, when it needs more space to
install newer packages.

The Cluster Monitor handles communication with the AliEn Job Broker
and gives configuration to JAs.  It gets ``heartbeats'' from the JAs.
If it gets no heartbeats from a JA, the existing job will get into
the ZOMBIE status (after 1.5 hours) and then it will expire (after 3 hours).

The site services include also a MonALISA client and File Transfer
Daemon (FTD), described in the following.

\subsection{Monitoring}
%
Since the AliEn Workload Management does not
depend directly on sophisticated monitoring, no special monitoring
tools were developed in AliEn. As the monitoring solution, ALICE has
adopted and further developed the Java-based MonALISA [40] framework
mentioned already in the previous section. The MonALISA system is
designed as an ensemble of autonomous multithreaded, self-describing
agent-based subsystems which are registered as dynamic services, and
together can collect and process large amounts of information [40].

The collected monitoring information is published via Web Service
for use by AliEn Optimizers or for visualization purposes. An
extension of the network simulation code which is a part of MonALISA
can provide a tool for optimization and understanding of the
performance of the AliEn Grid system.

\subsection{File Transfer}
%
This service provides the scheduled file transfer
functionality and is running at the Storage Elements contained in
the ALICE distributed storage cluster. The File Transfer Daemons
(FTD) perform file transfers between sites on user's behalf using a
suitable external transfer protocol (like e.g. bbFTP or GridFTP).
File transfers are requested and scheduled in exactly the same way
as production jobs, this time under the control of the File Transfer
Broker.

\subsection{Storage}
%
Experience with the performance of different types of storage
managers shows that the most advanced storage solution is the native
XRootD [33] manager described in section 3. It has been demonstrated
that with all other parameters being equal (protocol access speed
and security) the native XRootD storage clusters exhibit
substantially higher stability and availability. The ALICE
distributed system of native XRootD clusters is orchestrated by the
global redirector which allows interacting with the complete storage
pool as a unique storage.  All storages are on WAN (Wide Area
Network).

\subsection{AliEn Shell - aliensh}
%
To complete the brief description of AliEn, we mention the client
called AliEn shell. It provides a UNIX-shell-like environment with
an extensive set of commands which can be used to access AliEn Grid
computing resources and the AliEn virtual file system.  There are
three categories of commands: informative and convenience commands,
File Catalogue and Data Management commands and TaskQueue/Job
Management commands. The AliEn shell has been created about 4 years
ago and become a popular tool among the users for job handling and
monitoring.

\subsection{Concluding remarks}
%
AliEn is a high-level middleware adopted by
the ALICE experiment, which has been used and validated in massive
Monte Carlo events production since 2001, in end-user analysis since
2005 and during the real data management and processing since 2007.
Its capabilities comply with the requirements of the ALICE computing
model. In addition to modules needed to build a fully functional
Grid, AliEn provides interfaces to other Grid implementations
enabling the true Grid interoperability. The AliEn development will
be ongoing in the coming years following the architectural path
chosen at the start and more modules and functionalities are
envisaged to be delivered.

The Grid (AliEn/gLite/other) services are many and quite complex.
Nonetheless, they are working together, allowing to manage thousands
of CPUs and PBs of various storage types. The ALICE choice of single
Grid Catalogue, single Task Queue with internal prioritization and a
single storage access protocol (xrootd) has been beneficial from
user and Grid management viewpoint.



%%%%%%%%%%%%%%%%%%%% section 6 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{WLCG and ALICE performance during the 2010/2011 LHC data
taking}

In this section, we will discuss the experience and performance of
the WLCG in general and the ALICE Grid project in particular during
the real LHC data taking both during the proton and the lead ion
beam periods.

\subsection{LHC performance}
%
The LHC delivered the first pp collisions in the end of 2009, but
the stable operations startup was in March 2010. Since then, the
machine has been working amazingly well compared to other related
facilities. Already in 2009, the machine beaten the world record in
the beam energy and other records have followed. In 2010, the
delivered integrated luminosity was 18.1 pb${}^{-1}$ and already
during the first months of operation in 2011, the delivered
luminosity was 265 pb${}^{-1}$. This is about a quarter of the
complete target luminosity for 2010 and 2011 [60], which is supposed
to be sufficient to get the answer concerning the existence of the
Higgs boson. Also, as mentioned in section 1, the machine has beaten
the records concerning the stored energy and also the beam
intensity.

The target number of bunches per a beam of protons stated for 2011
was reached already in the middle of the year: 1380 bunches. The
final target luminosity of $10^{34}\ $cm${}^{-2}$s${}^{-1}$ is being
approached rapidly, at present it is about
$10^{33}\ $cm${}^{-2}$s${}^{-1}$ [61].


\subsection{WLCG performance}
%
The performance of the data handling by the WLCG has also been
surprisingly good. This wrapped up several years to the LHC startup,
when the WLCG and the experiments themselves were regularly
performing a number of stress-tests of their distributed computing
infrastructure and were gradually upgrading the systems using new
technologies. As a result, when the data started to flow from the
detectors, the performance of the distributed data handling
machinery was quite astounding.  All aspects of the Grid have really
worked for the LHC and have enabled the delivery of Physics results
incredibly quickly.

During 2010, 15 PetaBytes of data were written to tapes at the CERN
Tier-0 reaching the level expected from the original estimates for
the fully-tuned LHC operations, a nominal data taking year. As
mentioned in section 2, in average 2 PB of data per a month were
written to tapes at Tier-0 with the exception of the heavy ions
period when this number got about doubled and a world record was
reached with 225~TB written to tapes within one day [17], see
Figure~\ref{fig18}. The CERN Tier-0 moved altogether above 1~PB of
data per day [17].

%fig18
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig18.eps} %    ** if .eps don't need extension
\caption{A record in data tape recording: over
220~TB/day}\label{fig18}
\end{figure}


As mentioned in section 2, the mass storage system at the CERN
Tier-0 supported data rates at an average over the year of ~
2.5~GB/s IN with peaks up to 11~GB/s, and data was served at an
average rate of $\sim 7$~GB/s with peaks up to 25~GB/s.

The data processing went on without basic show-stoppers. The
workload management system was able to get about 1 million of jobs
running per day, see Figure~\ref{fig19}, and this load is
gradually going up. This translates into significant amounts of
computer time. Towards the end of 2010 there was a situation when
all of the available job slots at Tier-1s and Tier-2s were often
fully occupied. This has been showing up also during 2011, so the
WLCG collaboration has already now fully used all the available
computing resources. During 2010, the WLCG delivered about
100~CPU-millennia [17].

%fig19
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig19.eps} %    ** if .eps don't need extension
\caption{WLCG job profile}\label{fig19}
\end{figure}



As also briefly mentioned in section 2, the WLCG was very successful
concerning the number of individuals really using the grid to
perform their analysis. At the start of the project, there was a
concern that end users will be discouraged from using the grid due
to complexity of its structure and services. But thanks to the
effort of the WLCG and experiments themselves a reasonably simple
access interfaces were developed and the number of end users reached
up to 800 in the large experiments.

The distribution of the delivered CPU power between sites has been
basically according to the original design, but the Tier-2s provided
more than the expected 40\%: it was in fact 50\% or more of the
overall delivery, see section 2. Member countries pledged different
amounts of resources according to their capacities and have been
delivering accordingly.  So the concept of collaborative Grid
resource sharing really works and enables institutes worldwide to
share data, and provide resources to the common goals of the
collaboration.

\subsubsection{Network performance}
%
The key basis for building up a distributed system is the data
transfer infrastructure. The network which the WLCG operates today
is much in advance of what was anticipated in the time of writing
the WLCG TDR. The OPN [18], see also section 2, started as dedicated
fiber links from CERN to each of the Tier-1s with the throughput 10
Gbit/s. Today, there is a full redundancy in this network with the
original links doubled and with back-up links between Tier-1s
themselves. The OPN is a complicated system with many different
layers of hardware and software and getting it into the current
shape was a difficult task, which evidently paid-off.

The original concerns about the possible network unreliability and
insufficiency were not realized. The network infrastructure relying
on the OPN and the complementary GEANT, US-LHCNet and all the R\&E
national network infrastructures, extensively monitored and
continuously checked with the test transfer jobs, has never been a
problem in the data transfer except for occasional glitches. The
originally estimated sustained transfer rate of 1.3~GB/s from Tier-0
to Tier-1s was reached without problems and exceeded and reached up
to 5~GB/s. Within the OPN, a peak of 70~Gb/s was supported without
any problem during a re-processing campaign of one of the LHC
experiments, see Figure~\ref{fig20}.

%fig20
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig20.eps} %    ** if .eps don't need extension
\caption{WLCG OPN traffic in 2010 with a peak of 70
Gbit/s}\label{fig20}
\end{figure}



\subsubsection{Concluding remarks - WLCG}
%
The experience from the first year and a half of the LHC data taking
implies that the WLCG has built a truly working grid infrastructure.
The LHC experiments have their own distributed models and have used
the WLCG infrastructure to deliver Physics results within weeks
after the data recording which has never been achieved before. The
fact that a significant numbers of people are doing analysis on the
Grid, that all the resources are being used up to the limits and the
scientific papers are produced with an unprecedented speed is
proving an evident success of the WLCG mission.


\subsection{ALICE performance}
%
To conclude this section, we will briefly summarize the experience
and performance of the ALICE experiment. ALICE started extremely
successfully the processing of the LHC data in 2009: the data
collected during the first collisions delivered by the LHC on
November 23rd (2009) got processed and analyzed so fast that within
one week the article with the results from the first collisions was
accepted for publication as the first ever scientific paper with the
Physics results from the LHC collisions [62].

\subsubsection{Jobs}
%
During the data taking in 2010, ALICE collected 2.3~PB of raw data,
which represented about 1.2 million of files with the average file
size of 1.9~GB. The data processing chain has been performing
without basic problems.  The Monte Carlo simulation jobs together
with the raw data reconstruction and organized analysis (altogether
the organized production) represented almost 7 millions of
successfully completed jobs, which translates into 0.3 jobs/second.
The chaotic (end user) analysis made for 9 millions of successfully
completed jobs, which represents 0.4 jobs/s, consuming approximately
10\% of the total ALICE CPU resources (the chaotic analysis jobs are
in general shorter than the organized processing jobs).  In total,
there were almost 16 millions of successfully done jobs, which
translates to ~1 job/s and 90 thousands jobs/day. The complimentary
number of jobs which started running on the Grid but finished with
an error was in excess of this.

The running jobs profile got in peaks to 30 thousands of
concurrently running jobs (see Figure~\ref{fig21}) with more than
50\% of the CPU resources delivered by the Tier-2 centers. About
60\% of the total number of jobs represented the end user analysis
(see Figure~\ref{fig22}). In general, the user analysis already in
2010 was a resounding success, with almost 380 people actively using
the Grid. Since the chaotic analysis brings sometimes problems
concerning not completely perfect code resulting, e.g., in a high
memory consumption (cf. section 4), ALICE was running a mixture of
the organized production and end user jobs at all its sites, and
this scenario was working well.

%fig21
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig21.eps} %    ** if .eps don't need extension
\caption{ALICE running jobs profile 2010/2011}\label{fig21}
\end{figure}


%fig22
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig22.eps} %    ** if .eps don't need extension
\caption{Network traffic OUT by analysis jobs - 2010}\label{fig22}
\end{figure}



\subsubsection{Storage-2010}
%
The distributed storage system endured and was supporting an
enormous load. During 2010/2011, 25.15 PB of data (raw, ESDs, AODs,
Monte Carlo  productions) was written to xrootd Storage Elements
with the speed maximum of 621.1 MB/s. 59.97 PB  of data was read
from the xrootd Storage Elements, with the speed maximum of 1.285
GB/s, see Figure~\ref{fig23}.

%fig23
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig23.eps} %    ** if .eps don't need extension
\caption{Total network traffic at the ALICE Storage Elements -
2010/2011}\label{fig23}
\end{figure}


\subsubsection{Data taking 2011}
%
Constantly upgrading and extending its hardware resources and
updating the grid software, ALICE continued a successful LHC data
handling campaign in 2011. By September, the total volume of the
collected raw data was almost 1.7~PB with the first reconstruction
pass completed. 2011 was marked by massive user analysis on the
Grid. In May, the most important conference in the Heavy Ion Physics
community, Quark Matter 2011 (QM2011) [63], took place and was
preceded by an enormous end user analysis campaign. In average, 6
thousands end-user jobs were running all the time, which represents
almost 30\% of the CPU resources officially dedicated to ALICE (The
number of running jobs is higher than that most of the time due to
use of opportunistic resources). During the week before the QM2011,
there was a peak with 20 thousands of concurrently running end-user
jobs, see Figures~\ref{fig23},\ref{fig24}. The number of active Grid
users reached 411.

%fig24
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig24.eps} %    ** if .eps don't need extension
\caption{End-user jobs profile - 2011}\label{fig24}
\end{figure}


In total, the ALICE sites were running in average 21 thousands of
jobs with peaks up to 35~thousands (Figure~\ref{fig21}). The
resources ratio remained 50\% delivered by Tier-0 and Tier-1s to
50\% delivered by Tier-2s. Altogether, 69 sites were active in the
operations. The sites' availability and operability kept very stable
throughout the year. The gLite (now EMI) middleware, see section 3,
is mature and only a few changes are necessary. To the end of the
year 2011, a new AliEn version with new central services and user
client is expected to be ready for deployment.

In the beginning of the 2011 campaign, there was a concern that the
storage would be saturated. In fact the storage infrastructure was
performing basically without problems supporting the enormous load
from the end-user analysis and was getting ready for the Pb-Pb
operations. The network situation, as was already mentioned for the
WLCG in general, has been excellent and allowed for the operation
scenario where the hierarchical tiered structure got blurred, the
sites of all levels were well interconnected and running a similar
mixture of jobs. As a result, the ALICE Grid in a sense has been
working as a cloud.

\subsection{Concluding remarks - ALICE}
%
In general, similar to the overall characteristics of the WLCG
performance also the ALICE operations and data handling campaigns
were notably successful right from the beginning of the LHC startup,
making the Grid infrastructure operational and supporting a fast
delivery of Physics results. By September 2011, ALICE has published
15 scientific papers with the results from the LHC collisions and
more is on the way. Two papers [64,65] were marked as ``Suggested
reading'' by the Physical Review Letters editors and the paper [65]
was selected for the ``Viewpoint in Physics'' by Physical Review
Letters.


%fig25
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig25.eps} %    ** if .eps don't need extension
\caption{Pb-Pb collision event recorded by ALICE}\label{fig25}
\end{figure}



The full list of the ALICE papers published during 2009-2011 can be
found on [66]. One of the Pb-Pb collision events recorded by ALICE is
shown on Figure~\ref{fig25}.


%%%%%%%%%%%%%%%%%%%% section 7 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{Summary and Outlook}

This article is meant to be a short overview of the facts concerning
the Grid computing for HEP experiments, in particular for the
experiments at the CERN LHC. The experience gained during the LHC
operations in 2009-2011 has proven that for this community, the
existence of a well performing distributed computing
is necessary for the achievement and fast delivery of scientific
results. The existing WLCG infrastructure turned up to be able to
support the data production and processing thus fulfilling its
first-plan mission. It has been and will be continuously developing
into the future absorbing and giving rise to new technologies, like
the advances in networking, storage systems and inter-operability
between Grids and Clouds [67,68].

\subsection{Data management}
%
Managing the real data taking and processing in 2009-2011 provided
basic experience and a starting point for new developments. The
excellent performance of the network which was by far not
anticipated in the time of writing the WLCG (C)TDR shifted the
original concept of  computing models based on hierarchical
architecture to a more symmetrical mesh-like scenario. In original
design, the jobs are sent to sites holding the required data sets
and there are multiple copies of data spread over the system due to
anticipation that network will be unreliable or insufficient. It
turned out that some data sets were placed on sites and never
touched.

Based on the existing excellent network reliability and growing
throughput, the data models start to change along a dynamical
scenario. This includes sending data to a site just before a job
requires it, or reading files remotely over the network, use remote
(WAN) I/O to the running processes. Certainly, fetching over the
network one needed data file from a given data set which can contain
hundreds of files is more effective than a massive data sets
deployment and will spare storage resources and bring less network
load.

The evolution of the data management strategies is ongoing. It goes
towards caching of data rather than strict planned placement.  As
mentioned, the preferences go to fetching a file over the network
when a job needs it and to a kind of intelligent data pre-placement.
The remote access to data (either by caching on demand and/or by
remote file access) should be implemented.

\subsection{Network}
%
To improve the performance of the WLCG-operated network
infrastructure, the topology of LHC Open Network Environment (LHCONE [69])
is being developed and
built. This should be complementary to the existing OPN
infrastructure providing the inter-connectivity between Tier-2s and
Tier-1s and between Tier-2s themselves without putting an additional
load on the existing NREN infrastructures. As we learned during the
last years, the network is extremely important and better connected
countries do better [17].

\subsection{Resources}
%
During the 2010 data taking the available resources were sufficient
to cover the needs of experiments, but during 2011 the computing
slots as well as the storage capacities at sites started to be full.
Since the experience clearly shows that delivery of the Physics
results is limited by resources, the experiments are facing a
necessity of more efficient usage of existing resources. There are
task forces studying the possibility of using the next generations
computing and storage technologies. There is for instance a question
of using multicore processors which might go into the high
performance computing market while WLCG prefers usage of commodity
hardware.

\subsection{Operations}
%
Another important issue is sustainability and support
availability for the WLCG operations. The middleware used today for
the WLCG operations is considerably complex with many services
unnecessarily replicated in many places (like e.g. databases) mainly
due to original worries concerning network. The new conception is to
gradually search for more standard solutions instead of often highly
specialized middleware packages maintained and developed by WLCG.

\subsection{Clouds and Virtualization}
%
Among the new technologies, the Clouds is the right buzzword now and
the virtualization of resources comes along. The virtualization of
WLCG sites started prior to the first LHC collisions and has gone
quite far. It helps improving system management, provision of
services on demand, can make use of resources more effective and
efficient. Virtualization also enables to make use of industrial and
commercial solutions.

But, no matter what the current technologies advertise, the LHC
community will always use a Grid because the scientists need to
collaborate and share resources. No matter what technologies are
used underneath the  Grid, the collaborative sharing of resources
and the network of trust and all the security infrastructure
developed on the way of building the WLCG is of enormous value, not
only to WLCG community but to e-science in general. It allows people
to collaborate across the infrastructures.

%fig26
\begin{figure}[htb] % h-here, t-top, b-bottom
\centering
\includegraphics[width=13cm]{fig26.eps} %    ** if .eps don't need extension
\caption{Schema of StratusLab IaaS Cloud interoperability with a
Grid}\label{fig26}
\end{figure}



The basic operations like distributed data management, the high data
throughput and  the remote job submission can probably be more
cloud-like. There is a great interest among people to use commercial
Clouds resources, especially when the experiments see their
resources becoming full.

So, can we use Amazon or Google to do processing of data from LHC?
The point is, one can not be sure what the level of services will be
and what the IN/OUT bandwidth will be. This can in principle be
negotiated with these companies and may bring some level of
agreement. That in principle is doable.

But the preferred and more practical strategy for the future WLCG
development is to deploy over the WLCG resources Cloud interfaces,
managed with high level of virtualization. The Cloud and Grid
interfaces can be deployed in parallel or on top of each other. This
gives a way to evolve into a more standardized infrastructure and
allows to make a transparent use of commercial Clouds.

An example of this architecture is the CERN LXCloud [70] pilot
cluster. Implementation at CERN allows to present a Cloud interface
or to access other public or commercial Clouds. This is happening
with no change to any of the existing Grid services. Another
interesting example is the development of a comprehensive OpenSource
IaaS (Infrastructure as a Service) Cloud distribution within the
StratusLab project [68], see Figure~\ref{fig26}. Anyone can take the
code and deploy it on his site and have IaaS Cloud running on his
site. The project is focused on deploying Grid services on top of
this Cloud, 1) to be a service to existing European Grid
infrastructures and to enable these people to use Cloud-operated
resources and 2) because the developers consider the Grid services
very complex and making sure they run safely on this Cloud should
guarantee that also other applications will run without problems.



\subsection{Concluding remarks}
%
As we already stressed, the WLCG performance during the LHC data
taking in 2009-2011 was excellent and the basic mission of the WLCG
has been fulfilled: the data taking and processing is ongoing
without major show-stoppers, hundreds of people are using the Grid
to perform their analyses and unique scientific results are
delivered within weeks after the data was recorded. In addition, the
experience gained during this data taking ``stress test'' launched new
strategies to be followed on the way of the future WLCG development.
There are fundamental issues like the approaching lack of WLCG
resources and the expansion of new technologies like the Cloud
computing. In the time of writing this paper it looks like we will
see in the future some combination of Grid and Cloud technologies
will be adopted to operate the distributed computing infrastructures
used by the HEP experiments.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

%%% Without a bib file, write your references like this: **************
\begin{thebibliography}{100}

\bibitem{HEP}  D.H. Perkins:  Introduction to High Energy Physics, Cambridge
University Press,\\ 4th edition (2000), ISBN-13: 978-0521621960.\\
Procedings of 35th International Conference of High Energy Physics,
July 22-28, 2010, Paris, France,
     Proceedings of Science (PoS) electronic Journal: ICHEP 2010
%
\bibitem{QGP}  STAR Collaboration: Experimental and theoretical challenges in
the search for the quark gluon plasma: The STAR Collaboration's
     critical assessment of the evidence from RHIC collisions,
     Nucl.~Phys.~A757~(2005)~102-183.
%
\bibitem[3]{s1_3} CERN - the European Organization for Nuclear Research;
\newline\url{http://public.web.cern.ch/public/}
%
\bibitem[4]{s1_4}  The Large Hadron Collider at
CERN; \url{http://lhc.web.cern.ch/lhc/};
\newline\url{http://public.web.cern.ch/public/en/LHC/LHC-en.html}
%
\bibitem[5]{s1_5} ALICE
Collaboration: \url{http://aliceinfo.cern.ch/Public/Welcome.html}
%
\bibitem[6]{s1_6} ATLAS Collaboration: \url{http://atlas.ch/}
%
\bibitem[7]{s1_7}  CMS Collaboration: \url{http://cms.web.cern.ch/}
%
\bibitem[8]{s1_8} LHCb Collaboration: \url{http://lhcb-public.web.cern.ch/lhcb-public/}
%
\bibitem[9]{s1_9} W.N. Cottingham and D.A. Greenwood: An Introduction to the Standard Model of
Particle Physics, Cambridge University Press, 2nd edition (2007), ISBN-13: 978-0521852494
%
\bibitem[10]{s1_10} Worldwide LHC Computing Grid:
\newline\url{http://public.web.cern.ch/public/en/lhc/Computing-en.html}
%
% S2
%
\bibitem[11]{s2_1} LHC Computing Grid: Technical Design Report,
\newline\url{http://lcg.web.cern.ch/LCG/tdr/}
%
\bibitem[12]{s2_2} I. Foster and C. Kesselman. The Grid: Blueprint for a New Computing Infrastructure.
Morgan Kaufmann, 1999;\\
     I. Foster et al: The Anatomy of the Grid: Enabling Scalable Virtual Organizations,
     International Journal of High Performance
     Computing Applications Vol.15(2001), p.200.
%
\bibitem[13]{s2_3} WLCG Memorandum of Understanding,
\newline\url{http://lcg.web.cern.ch/lcg/mou.htm}
%
\bibitem[14]{s2_4} EGI - The European Grid Initiative; \url{http://web.eu-egi.eu/}
%
\bibitem[15]{s2_5} OSG - The Open Science Grid,
\newline\url{http://www.opensciencegrid.org/};
\newline\url{https://osg-ress-1.fnal.gov:8443/ReSS/ReSS-prd-History.html}
%
\bibitem[16]{s2_6} I. Legrand et al: MONARC Simulation Framework, ACAT'04, Tsukuba, Japan,2004;
\newline\url{http://monarc.cacr.caltech.edu:8081/www_monarc/monarc.htm}
%
\bibitem[17]{s2_7} I. Bird: LHC Computing: After the first year with data, TERENA
Networking Conference (TNC2011), Prague, 2011,
       \newline\url{https://tnc2011.terena.org/web/media/archive/7A}
%
\bibitem[18]{s2_8} LHCOPN - The Large Hadron Collider Optical Private Network,
\newline\url{https://twiki.cern.ch/twiki/bin/view/LHCOPN/WebHome}
%
\bibitem[19]{s2_9} The GEANT Project, \url{http://archive.geant.net/}
%
\bibitem[20]{s2_10} USLHCNet: High speed TransAtlantic network for the LHC community,
\newline\url{http://lhcnet.caltech.edu/}
%
% S3
%
\bibitem[21]{s3_3} Virtual Organisation: \url{http://technical.eu-egee.org/index.php?id=147}
%
\bibitem[22]{s3_4} The European Middleware Initiative:
\url{http://www.eu-emi.eu/home}
%
\bibitem[23]{s3_5} The Globus Toolkit: \url{http://www-unix.globus.org/toolkit/}
%
\bibitem[24]{s3_6} OMII - The Open Middleware Infrastructure Institute:
\url{http://www.omii.ac.uk/}
%
\bibitem[25]{s3_7} The Virtual Data Toolkit, \url{http://vdt.cs.wisc.edu/}
%
\bibitem[26]{s3_8} P.~Saiz~et~al.,  AliEn-ALICE environment on the GRID,\\
Nucl.~Instrum.~Meth.~A502~(2003)~437; \url{http://alien2.cern.ch/}
%
\bibitem[27]{s3_9} Computing Element: \url{http://glite.cern.ch/lcg-CE/}
%
\bibitem[28]{s3_10} Workload Management System: \url{http://glite.cern.ch/glite-WMS/}
%
\bibitem[29]{s3_11} The CREAM (Computing Resource Execution And Managemen) Service,
\newline\url{http://glite.cern.ch/glite-CREAM/}
%
\bibitem[30]{s3_12} Storage Element: \url{http://glite.cern.ch/glite-SE_dpm_mysql/}
%
\bibitem[31]{s3_13} dCache: \url{http://www.dcache.org/}
%
\bibitem[32]{s3_14} The Disk Pool Manager:
\newline\url{https://www.gridpp.ac.uk/wiki/Disk_Pool_Manager};
\newline\url{https://twiki.cern.ch/twiki/bin/view/LCG/DataManagementTop}
%
\bibitem[33]{s3_15} XRootD:
\newline\url{http://project-arda-dev.web.cern.ch/project-arda-dev/xrootd/site/index.html}
%
\bibitem[34]{s3_16} SLAC (Stanford Linear Accelerator Center):
\url{http://slac.stanford.edu/}
%
\bibitem[35]{s3_17} INFN - The National Institute of Nuclear Physics:
\newline\url{http://www.infn.it/indexen.php}
%
\bibitem[36]{s3_18} R. Brun and F. Rademakers, ROOT: An object oriented data analysis framework,\\
Nucl.~Instrum.~Meth.~A389~(1997)~81; \url{http://root.cern.ch}
%
\bibitem[37]{s3_19} The VO-box: \url{http://glite.cern.ch/glite-VOBOX/}
%
% S4
%
\bibitem[38]{s4_1} ALICE Experiment Computing TDR:
\newline\url{http://aliceinfo.cern.ch/Collaboration/Documents/TDR/Computing.html}
%
\bibitem[39]{s4_5} CERN Advanced Storage Manager:
\newline\url{http://castor.web.cern.ch/castor/}
%
\bibitem[40]{s4_6} Monitoring Agents using a Large Integrated Services
Architecture:
\newline\url{http://monalisa.cern.ch/monalisa.html};\\
         C.~Grigoras et al., Automated agents for management and control of the ALICE Computing Grid,
         Proceedings of the 17th Int. Conf. CHEP 2009,
         Prague, March 21-27, 2009, J.~Phys.: Conf.~Ser.~219,~062050.
%
\bibitem[41]{s4_7} ALICE raw data production cycles:
\newline\url{http://alimonitor.cern.ch/production/raw.jsp}
%
\bibitem[42]{s4_8} Monitoring of Analysis trains in ALICE:
\newline\url{http://alimonitor.cern.ch/prod/}
%
\bibitem[43]{s4_9} ALICE simulation framework:
\newline\url{http://aliceinfo.cern.ch/Offline/Activities/Simulation/index.html}
%
\bibitem[44]{s4_10} ALICE MC simulation cycles:
\newline\url{http://alimonitor.cern.ch/job_details.jsp}
%
\bibitem[45]{s4_11} AliRoot: \url{http://aliceinfo.cern.ch/Offline/AliRoot/Manual.html}
%
\bibitem[46]{s4_12} GEANT3-Detector Description and Simulation Tool:
\newline\url{http://wwwasd.web.cern.ch/wwwasd/geant/}
%
\bibitem[47]{s4_13} FLUKA-Particle Physics MonteCarlo Simulation package:
\newline\url{http://www.fluka.org/fluka.php}
%
\bibitem[48]{s4_14} Pythia6: \url{http://projects.hepforge.org/pythia6/};\\
Pythia8: \url{http://home.thep.lu.se/~torbjorn/pythiaaux/present.html}
%
\bibitem[49]{s4_15} Xin-Nian Wang and Miklos Gyulassy: HIJING: A Monte Carlo model for
multiple jet production in pp, pA and AA collisions,\\ Phys.~Rev.~D44~(1991),~3501;
         \newline\url{http://www-nsdth.lbl.gov/~xnwang/hijing/}
%
\bibitem[50]{s4_16} ALICE Offline policy:
\newline\url{http://aliceinfo.cern.ch/Offline/General-Information/Offline-Policy.html}
%
\bibitem[51]{s4_17} ALICE Computing sites:
\newline\url{http://pcalimonitor.cern.ch:8889/reports/};\\
ALICE Distributed Storage: \newline\url{http://pcalimonitor.cern.ch/stats?page=SE/table}
%
\bibitem[52]{s4_18} Yves Schutz: Computing resources 2011-2013, ALICE Computing Board
Sept.~1st, 2011:
\newline\url{http://indico.cern.ch/materialDisplay.py?contribId=3&materialId=2&confId=153622};\\
\newline\url{https://twiki.cern.ch/twiki/bin/view/FIOgroup/TsiBenchHEPSPEC}
%
% S5
%
\bibitem[53]{s5_2}  gLite-Lightweight Middleware for Grid Computing,
\newline\url{http://glite.cern.ch/}
%
\bibitem[54]{s5_3}  ARC-The Advanced Resource Connector middleware,
\newline\url{http://www.nordugrid.org/arc/about-arc.html}
%
\bibitem[55]{s5_5} The AliEn Shell-aliensh,
         AliEn User Interfaces:
\newline\url{http://project-arda-dev.web.cern.ch/project-arda-dev/alice/apiservice/guide/guide-1.0.html#_Toc156731986};\\
         ALICE Grid Analysis:
\newline\url{http://project-arda-dev.web.cern.ch/project-arda-dev/alice/apiservice/AA-UserGuide-0.0m.pdf}
%
\bibitem[56]{s5_7}  The PANDA Experiment: \url{http://www-panda.gsi.de/}
%
\bibitem[57]{s5_8} GAS-Grid Access Service in AliEn:
         P. Buncic et al, The architecture of the AliEn system,
         Proc of the Conference on Computing in High Energy Physics and Nuclear Physics
         2004 (CHEP'04), Interlaken, Switzerland,
         \newline\url{http://cdsweb.cern.ch/record/865533/files/p951.pdf}
%
\bibitem[58]{s5_9} VOMS-Virtual Organization Membership Service:
\newline\url{http://glite.web.cern.ch/glite/packages/R3.1/deployment/glite-VOMS_mysql/glite-VOMS_mysql.asp}
%
\bibitem[59]{s5_10} Job statuses in AliEn:
\newline\url{http://pcalimonitor.cern.ch/show?page=jobStatus.html}
%
% S6
%
\bibitem[60]{s6_1} LHC Design Report:
\url{http://lhc.web.cern.ch/lhc/LHC-DesignReport.html}
%
\bibitem[61]{s6_2} LHC Performance and Statistics:
\newline\url{https://lhc-statistics.web.cern.ch/LHC-Statistics/}
%
\bibitem[62]{s6_5} The ALICE Collaboration: First proton-proton
collisions at the LHC as observed with the ALICE detector:
measurement of the charged-particle
        pseudorapidity density at $\sqrt{s}=900$ GeV, Eur.~Phys.~J.~C65~(2010),~111-125.
%
\bibitem[63]{s6_6} Quark Matter 2011: \url{http://qm2011.in2p3.fr/}
%
\bibitem[64]{s6_7} The ALICE
Collaboration: Charged-Particle Multiplicity Density at Midrapidity
in Central Pb-Pb Collisions at $\sqrt{s_{NN}}=2.76$ TeV,
        Phys.~Rev.~Lett.~105~(2010),~252301.
%
\bibitem[65]{s6_8} The ALICE Collaboration: Elliptic Flow of Charged Particles
in Pb-Pb Collisions at $\sqrt{s_{NN}}=2.76$ TeV,
Phys.~Rev.~Lett.~105~(2010),~252302.
%
\bibitem[66]{s6_9} Physics Publications of the ALICE
Collaboration in Refereed Journals,
\newline\url{http://aliceinfo.cern.ch/Documents/generalpublications}
%
% S7
%
\bibitem[67]{s7_1} I. Foster et al: Cloud Computing and Grid Computing
360-Degree Compared, Proc. of the Grid Computing Environments
Workshop, 2008. GCE '08, Austin, Texas,
\newline\url{http://arxiv.org/ftp/arxiv/papers/0901/0901.0131.pdf}
%
\bibitem[68]{s7_2} C. Loomis: StratusLab: Enhancing Grid Infrastructures with
Cloud and Virtualization Technologies, TERENA Networking Conference
(TNC2011),Prague, 2011,
\newline\url{https://tnc2011.terena.org/web/media/archive/11C}
%
\bibitem[69]{s7_3} LHCONE-LHC Open Network Environment:
\newline\url{http://lhcone.net/}
%
\bibitem[70]{s7_5} LXCloud:
\url{https://twiki.cern.ch/twiki/bin/view/FIOgroup/LxCloud}




%\bibitem[Arai \& Kragic, 1999]{arai99} Arai, T. \& Kragic, D. (1999). Name of paper, In: \emph{Name of Book in Italics}, Name(s) of Editor(s), (Ed.), page numbers (first-last), Publisher, ISBN, Place of publication

%\bibitem[Arkin, 2004]{arkin04} Arkin, D. (2004). \emph{My Life}, Arkin Publishing, Arkinson.

%\bibitem[Li et al., 1996]{li96} Li, B.; Xu, Y. \& Choi, J. (1996). Title of conference paper,  \emph{Proceedings of xxx xxx in italics}, pp. 14-17, ISBN, conference location, month and year, Publisher, City

%\bibitem[Lima et al., 2004]{lima04} Lima, P.; Bonarini, A. \& Mataric, M. (2004). \emph{Name of Book in Italics}, Publisher, ISBN, Place of Publication.

%\bibitem[Mataric \& Brooks, 1999]{mataric99} Mataric M. \& Brooks, R. (1999). To whom it may concern. \emph{Journal of Everything}, Vol. $\infty$, No. $\aleph_0$, Jan -1999, -10 -- -5, ISSN 00-XY-A

%\bibitem[Siegwart, 2001]{siegwart01} Siegwart, R. (2001). Name of paper. \emph{Name of Journal in Italics}, Vol., No., (month and year of the edition) page numbers (first-last), ISSN

%\bibitem[Siegwart et al., 2006]{siegwart06} Siegwart, R.; Gross, S.; Klein L. (2006). The Singularity has gone. \emph{Future beyond Science}, Vol. 0, No. 0, April 3000, 1--1 000 000, ISSN 00-0000-00-00Y

\end{thebibliography}

%%% With a bib file, include it! *************************************


\end{document}
